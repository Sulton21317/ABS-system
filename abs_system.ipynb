{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T08:53:36.465018200Z",
     "start_time": "2023-11-27T08:53:30.101876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\UzDev/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-11-26 Python-3.10.9 torch-2.1.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# for gpu\u001B[39;00m\n\u001B[0;32m     11\u001B[0m model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124multralytics/yolov5\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom\u001B[39m\u001B[38;5;124m'\u001B[39m, path\u001B[38;5;241m=\u001B[39mmodel_path)  \u001B[38;5;66;03m# local model\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Load the video\u001B[39;00m\n\u001B[0;32m     15\u001B[0m video \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mVideoCapture(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrimmedVideo_11.mp4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1156\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1157\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m   1158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m-> 1160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:660\u001B[0m, in \u001B[0;36mAutoShape._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    659\u001B[0m     \u001B[38;5;66;03m# Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers\u001B[39;00m\n\u001B[1;32m--> 660\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    661\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpt:\n\u001B[0;32m    662\u001B[0m         m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdmb \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# Detect()\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\yolo.py:155\u001B[0m, in \u001B[0;36mBaseModel._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;66;03m# Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers\u001B[39;00m\n\u001B[1;32m--> 155\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    156\u001B[0m     m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# Detect()\u001B[39;00m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(m, (Detect, Segment)):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    829\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 833\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1157\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m-> 1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:289\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    285\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    286\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    287\u001B[0m     )\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 289\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    291\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    292\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    293\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# YOLOv5 modelini yuklaymiz\n",
    "model_path = 'yolov5s.pt'\n",
    "\n",
    "device = \"cpu\"  # cpu uchun\n",
    "# device = 0  #  gpu uchun\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)  # local model\n",
    "model.to(device)\n",
    "\n",
    "# video yuklaymiz\n",
    "video = cv2.VideoCapture('trimmedVideo_11.mp4')\n",
    "\n",
    "\n",
    "width, height = 1280, 720\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Qayta ishlangan videoni saqlash uchun VideoWriter ob'ektini yarating\n",
    "_output1 = cv2.VideoWriter('_output_ABS.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# Ko'pburchak ROIni aniqlang (Region of intersets)\n",
    "roi_points = np.array([[400, 720], [400, 400], [870, 400], [870, 720]], np.int32)\n",
    "\n",
    "#Ob'ektning haqiqiy o'lchamlarini aniqlaymiz\n",
    "object_width = 50  # in centimeters\n",
    "\n",
    "# Kameraning fokus uzunligini kiritamiz.\n",
    "focal_length = 1000  # in pixels\n",
    "\n",
    "# CWS uchun masofa oralig'i\n",
    "dist_ = 12\n",
    "\n",
    "# Videoning har bir kadrini qayta ishlash\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    success, frame = video.read()\n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Ko'pburchak ROIni chizish\n",
    "    cv2.polylines(frame, [roi_points], True, (0, 200, 0), 2)\n",
    "\n",
    "    # ROI ichidagi uchta gorizontal chiziqning y-koordinatalarini hisoblash\n",
    "    line_y1 = 600\n",
    "    line_gap = 10\n",
    "    line_ys = [line_y1 + i * line_gap for i in range(dist_)]\n",
    "\n",
    "    # Chiziq ranglarini va kesishgan chiziq sonini boshlang\n",
    "    line_colors = [(255, 0, 0) for _ in range(dist_)]\n",
    "    crossed_lines = []\n",
    "\n",
    "    # Kadrda ob'ektni aniqlashni amalga oshirish\n",
    "    results = model(frame, size=320)\n",
    "    detections = results.pred[0]\n",
    "\n",
    "    # Ramkaning o'rtasida bo'linish chizig'ini tortish\n",
    "    height, width, _ = frame.shape\n",
    "    cv2.line(frame, (width // 2, 0), (width // 2, height), (160, 160, 160), 2)\n",
    "\n",
    "    # Chegaraning markazlari ROI ichida yoki yo'qligini tekshirish\n",
    "    for detection in detections:\n",
    "        xmin = detection[0]\n",
    "        ymin = detection[1]\n",
    "        xmax = detection[2]\n",
    "        ymax = detection[3]\n",
    "        score = detection[4]\n",
    "        class_id = detection[5]\n",
    "\n",
    "\n",
    "        # Chegara ball\n",
    "        if score >= 0.4:\n",
    "\n",
    "            # Markaz koordinatalarini hisoblash\n",
    "            if xmin < frame.shape[1] // 2:\n",
    "                # Ramkaning chap tomoni\n",
    "                centroid_x = int(xmax)\n",
    "                centroid_y = int(ymax)\n",
    "            else:\n",
    "                # Ramkaning o'ng tomoni\n",
    "                centroid_x = int(xmin)\n",
    "                centroid_y = int(ymax)\n",
    "\n",
    "            # Chegaraning markazlari ROI ichida yoki yo'qligini tekshirish\n",
    "            if cv2.pointPolygonTest(roi_points, (centroid_x, centroid_y), False) > 0:\n",
    "                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "                    # Chegara qutisi biron bir chiziqqa tegib yoki yo'qligini tekshirish\n",
    "                for i, line_y in enumerate(line_ys):\n",
    "                    if ymax >= line_y:\n",
    "                        line_colors[i] = (0, 0, 255)  # Chiziq rangini qizil rangga o'zgartirish\n",
    "                        crossed_lines.append(i + 1)  # Ro'yxatga kesishgan chiziq raqamini qo'shish\n",
    "\n",
    "                # Ob'ektgacha bo'lgan masofani hisoblash\n",
    "                distance = (object_width * focal_length) / (xmax - xmin)\n",
    "\n",
    "                # Chegara ramkasini chizish va masofani ko'rsatish\n",
    "                cv2.rectangle(frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, f\"Masofa: {distance:.2f} cm\", (int(xmin), int(ymin) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "    for line_y, color in zip(line_ys, line_colors):\n",
    "        cv2.line(frame, (roi_points[0][0], line_y), (roi_points[2][0], line_y), color, 2)\n",
    "\n",
    "    # Kesilgan chiziq raqamlarini chop etish\n",
    "    if crossed_lines:\n",
    "        cv2.putText(frame, 'Tormoz', (1000- 25, 100 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        crossed_lines_str = ', '.join(str(line_num) for line_num in crossed_lines)\n",
    "        cv2.putText(frame, str(max(crossed_lines)), (1000 , 100 + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "        if max(crossed_lines) == 4 and max(crossed_lines) <= 5:\n",
    "            cv2.putText(frame, 'OLDINDA To\\'qnashuv ogohlantirish', (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        elif max(crossed_lines) == 6 and max(crossed_lines) <= 8:\n",
    "            cv2.putText(frame, 'To\\'qnashuv haqida OGOHLANTIRISH', (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        elif 9 <= max(crossed_lines) <= 11:\n",
    "            cv2.putText(frame, 'DIQQAT BERING va NAZORATGA OLING', (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        elif max(crossed_lines) >= 11:\n",
    "            cv2.putText(frame, 'Favqulodda To\\'xtash ..!!', (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "    # Ramkani ko'rsatish\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    # Chiqarilgan videoga ishlov berilgan kadrni yozish\n",
    "    _output1.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Videoga olish va yozish ob'ektlarini qo'yib yuborish\n",
    "video.release()\n",
    "_output1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T12:17:13.486491Z",
     "start_time": "2023-11-26T12:17:13.470991600Z"
    }
   },
   "id": "d653421bd936775c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T12:11:11.830601500Z",
     "start_time": "2023-11-26T12:11:11.820639800Z"
    }
   },
   "id": "76af48bf90e09e54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "79fe0d9eb9ec99b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
